{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6936aaa128ffb684",
   "metadata": {},
   "source": [
    "# Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1678367e64f56efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cu121\n",
      "CUDA: True\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA:\", torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a0aad29c18be0",
   "metadata": {},
   "source": [
    "Load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "654a5a2cd1f018c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8ad64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36afdbb6",
   "metadata": {},
   "source": [
    "# Converting pdf to document structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1657de872aca3ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "MACHINE LEARNING  \n",
      "[R17A0534] \n",
      "LECTURE NOTES \n",
      " \n",
      "B.TECH IV YEAR – I SEM(R17) \n",
      "(2020-21) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "DEPARTMENT OF \n",
      "COMPUTER SCIENCE AND ENGINEERING \n",
      "MALLA REDDY COLLEGE OF ENGINEERING & \n",
      "TECHNOLOGY \n",
      "(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "file_path = r'D:\\Coding\\Learning\\LLMs\\RAG\\Data\\Machine_learning.pdf'\n",
    "\n",
    "loader = PyMuPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "print(docs[0].page_content[:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2dcd643aee5f365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d57c095f184f0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IV Year B. Tech. CSE –II Sem   \\n \\n \\n \\n \\n \\n                L   T/P/D   C  \\n  4   1/- / -   3  \\n(R17A0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].page_content[:100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9449f951",
   "metadata": {},
   "source": [
    "# Cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cbcfe5b5976f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleaning_text(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    text = re.sub(r'\\n+', '\\n', text)     # collapse newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)      # collapse spaces\n",
    "    text = re.sub(r'Page \\d+', '', text)  # remove page numbers\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c9d6a1",
   "metadata": {},
   "source": [
    "# Cleaning and division of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523df3342d61de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 120 raw elements from: D:\\Coding\\Learning\\LLMs\\RAG\\Data\\Machine_learning.pdf\n",
      "\n",
      "Merged 120 fragments into 119 full pages.\n",
      "\n",
      "Page 0\n",
      "MACHINE LEARNING [R17A0534] LECTURE NOTES B.TECH IV YEAR – I SEM(R17) (2020-21) DEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING MALLA REDDY COLLEGE OF ENGINEERING & TECHNOLOGY (Autonomous Institution – ...\n",
      "\n",
      "Page 1\n",
      "IV Year B. Tech. CSE –II Sem L T/P/D C 4 1/- / - 3 (R17A0534) Machine Learning Objectives:  Acquire theoretical Knowledge on setting hypothesis for pattern recognition.  Apply suitable machine learn ...\n",
      "\n",
      "Page 2\n",
      "TEXT BOOKS: 1. Ethem Alpaydin, ”Introduction to Machine Learning”, MIT Press, Prentice Hall of India, 3rd Edition2014. 2. Mehryar Mohri, Afshin Rostamizadeh, Ameet Talwalkar ” Foundations of Machine L ...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# -----------------------------\n",
    "# SETTINGS\n",
    "# -----------------------------\n",
    "MIN_TEXT_LENGTH = 40   # Ignore very tiny text fragments\n",
    "\n",
    "# -----------------------------\n",
    "# VARIABLES / CONTAINERS\n",
    "# -----------------------------\n",
    "final_documents = []       # This will hold page-level documents\n",
    "page_text_buffer = \"\"      # Temporary text storage for current page\n",
    "current_page_number = None # Track which page we are on\n",
    "\n",
    "# Get file name from metadata safely\n",
    "source_file = docs[0].metadata.get(\"source\", \"unknown.pdf\") if docs else \"unknown.pdf\"\n",
    "\n",
    "print(f\"Processing {len(docs)} raw elements from: {source_file}\")\n",
    "\n",
    "# -----------------------------\n",
    "# MAIN LOOP\n",
    "# -----------------------------\n",
    "for element in docs:\n",
    "\n",
    "    # Clean text using your custom function\n",
    "    cleaned_text = cleaning_text(element.page_content)\n",
    "\n",
    "    # Skip very small text like headers, page numbers, etc.\n",
    "    if len(cleaned_text) < MIN_TEXT_LENGTH:\n",
    "        continue\n",
    "\n",
    "    # Get page number safely\n",
    "    page_number = element.metadata.get(\"page_number\") or element.metadata.get(\"page\", 1)\n",
    "\n",
    "    # -------------------------\n",
    "    # PAGE CHANGE DETECTION\n",
    "    # -------------------------\n",
    "    if current_page_number is not None and page_number != current_page_number:\n",
    "        \n",
    "        # Save previous page content\n",
    "        final_documents.append(\n",
    "            Document(\n",
    "                page_content=page_text_buffer.strip(),\n",
    "                metadata={\n",
    "                    \"source\": source_file,\n",
    "                    \"page\": current_page_number\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Start buffer for new page\n",
    "        page_text_buffer = cleaned_text\n",
    "\n",
    "    else:\n",
    "        # Same page → keep adding text\n",
    "        page_text_buffer += \" \" + cleaned_text\n",
    "\n",
    "    # Update current page tracker\n",
    "    current_page_number = page_number\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# FINAL SAVE (LAST PAGE)\n",
    "# -----------------------------\n",
    "if page_text_buffer:\n",
    "    final_documents.append(\n",
    "        Document(\n",
    "            page_content=page_text_buffer.strip(),\n",
    "            metadata={\n",
    "                \"source\": source_file,\n",
    "                \"page\": current_page_number\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# VERIFICATION\n",
    "# -----------------------------\n",
    "print(f\"\\nMerged {len(docs)} fragments into {len(final_documents)} full pages.\")\n",
    "\n",
    "for doc in final_documents[:3]:\n",
    "    print(f\"\\nPage {doc.metadata['page']}\")\n",
    "    print(doc.page_content[:200], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff814d0db3f6842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06079ea2",
   "metadata": {},
   "source": [
    "# Chunking of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12911a7d198d5798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting documents into RAG-friendly chunks...\n",
      "Original Page Documents: 119\n",
      "Generated RAG Chunks: 275\n",
      "\n",
      "--- Chunk Preview ---\n",
      "MACHINE LEARNING [R17A0534] LECTURE NOTES B.TECH IV YEAR – I SEM(R17) (2020-21) DEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING MALLA REDDY COLLEGE OF ENGINEERING & TECHNOLOGY (Autonomous Institution – ...\n",
      "Metadata: {'source': 'D:\\\\Coding\\\\Learning\\\\LLMs\\\\RAG\\\\Data\\\\Machine_learning.pdf', 'page': 0, 'start_index': 0}\n",
      "\n",
      "--- Chunk Preview ---\n",
      "IV Year B. Tech. CSE –II Sem L T/P/D C 4 1/- / - 3 (R17A0534) Machine Learning Objectives:  Acquire theoretical Knowledge on setting hypothesis for pattern recognition.  Apply suitable machine learn ...\n",
      "Metadata: {'source': 'D:\\\\Coding\\\\Learning\\\\LLMs\\\\RAG\\\\Data\\\\Machine_learning.pdf', 'page': 1, 'start_index': 0}\n",
      "\n",
      "--- Chunk Preview ---\n",
      "Functions, K Nearest Neighbors. Introduction to clustering, K-means clustering, K-Mode Clustering. UNIT III: Ensemble and Probabilistic Learning Model Combination Schemes, Voting, Error-Correcting Out ...\n",
      "Metadata: {'source': 'D:\\\\Coding\\\\Learning\\\\LLMs\\\\RAG\\\\Data\\\\Machine_learning.pdf', 'page': 1, 'start_index': 1003}\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# -----------------------------------\n",
    "# TEXT SPLITTING CONFIGURATION\n",
    "# -----------------------------------\n",
    "# These values work well for technical books / PDFs\n",
    "CHUNK_SIZE = 1200      # Max characters per chunk\n",
    "CHUNK_OVERLAP = 200    # Shared context between chunks\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    add_start_index=True  # Useful for debugging / tracing later\n",
    ")\n",
    "\n",
    "print(\"\\nSplitting documents into RAG-friendly chunks...\")\n",
    "\n",
    "# -----------------------------------\n",
    "# SPLITTING PROCESS\n",
    "# -----------------------------------\n",
    "rag_chunks = text_splitter.split_documents(final_documents)\n",
    "\n",
    "# -----------------------------------\n",
    "# VERIFICATION\n",
    "# -----------------------------------\n",
    "print(f\"Original Page Documents: {len(final_documents)}\")\n",
    "print(f\"Generated RAG Chunks: {len(rag_chunks)}\")\n",
    "\n",
    "# Preview first few chunks\n",
    "for chunk in rag_chunks[:3]:\n",
    "    print(\"\\n--- Chunk Preview ---\")\n",
    "    print(chunk.page_content[:200], \"...\")\n",
    "    print(\"Metadata:\", chunk.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6628ea68a58fa655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='IV Year B. Tech. CSE –II Sem L T/P/D C 4 1/- / - 3 (R17A0534) Machine Learning Objectives:  Acquire theoretical Knowledge on setting hypothesis for pattern recognition.  Apply suitable machine learning techniques for data handling and to gain knowledge from it.  Evaluate the performance of algorithms and to provide solution for various real world applications. UNIT I: Introduction to Machine Learning Introduction ,Components of Learning , Learning Models , Geometric Models, Probabilistic Models, Logic Models, Grouping and Grading, Designing a Learning System, Types of Learning, Supervised, Unsupervised, Reinforcement, Perspectives and Issues, Version Spaces, PAC Learning, VC Dimension. UNIT II: Supervised and Unsupervised Learning Decision Trees: ID3, Classification and Regression Trees, Regression: Linear Regression, Multiple Linear Regression, Logistic Regression, Neural Networks: Introduction, Perception, Multilayer Perception, Support Vector Machines: Linear and Non-Linear, Kernel Functions, K Nearest Neighbors. Introduction to clustering, K-means clustering, K-Mode Clustering. UNIT III: Ensemble and Probabilistic Learning Model Combination Schemes, Voting, Error-Correcting' metadata={'source': 'D:\\\\Coding\\\\Learning\\\\LLMs\\\\RAG\\\\Data\\\\Machine_learning.pdf', 'page': 1, 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "print(rag_chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ba33f4204db03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rag_chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dad213",
   "metadata": {},
   "source": [
    "# Loading the embedding model - all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "772711e5b561a776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\Learning\\LLMs\\RAG\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import torch\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: EMBEDDING MODEL\n",
    "# -------------------------------\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"   # 384 dimensions\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_kwargs={\"device\": DEVICE},\n",
    "    encode_kwargs={\"normalize_embeddings\": False}\n",
    ")\n",
    "\n",
    "print(\"Embedding model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa155a4",
   "metadata": {},
   "source": [
    "# Building the faiss database and storing the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "379a88ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building FAISS Vector Database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\Learning\\LLMs\\RAG\\.venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS DB Built Successfully!\n",
      "Saved at: D:\\Coding\\Learning\\LLMs\\RAG\\faiss_db\n",
      "Total Chunks Stored: 275\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------------\n",
    "# STEP 2: BUILD FAISS DATABASE\n",
    "# -----------------------------------\n",
    "\n",
    "FAISS_PATH = r\"D:\\Coding\\Learning\\LLMs\\RAG\\faiss_db\"\n",
    "\n",
    "print(\"\\nBuilding FAISS Vector Database...\")\n",
    "\n",
    "# Create FAISS DB from documents\n",
    "vector_db = FAISS.from_documents(\n",
    "    documents=rag_chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# Save DB locally\n",
    "vector_db.save_local(FAISS_PATH)\n",
    "\n",
    "print(\"FAISS DB Built Successfully!\")\n",
    "print(f\"Saved at: {FAISS_PATH}\")\n",
    "print(f\"Total Chunks Stored: {len(rag_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc811f",
   "metadata": {},
   "source": [
    "# Loading faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e1bc19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading FAISS Database...\n",
      "FAISS Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# -----------------------------------\n",
    "# STEP 3: LOAD EXISTING FAISS DB\n",
    "# -----------------------------------\n",
    "\n",
    "FAISS_PATH = r\"D:\\Coding\\Learning\\LLMs\\RAG\\faiss_db\"\n",
    "\n",
    "print(\"\\nLoading FAISS Database...\")\n",
    "\n",
    "vector_db = FAISS.load_local(\n",
    "    FAISS_PATH,\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True   # required\n",
    ")\n",
    "\n",
    "print(\"FAISS Loaded Successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910ff68b",
   "metadata": {},
   "source": [
    "# Testing a query via cosine similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd44257b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1\n",
      "the cons of ANN networks, which are a flourishing science branch, are eliminated individually, and their pros are increasing day by day. It means that artificial neural networks will turn into an irreplaceable part of our lives progressively important.” How do artificial neural networks work? Artifi\n",
      "{'source': 'D:\\\\Coding\\\\Learning\\\\LLMs\\\\RAG\\\\Data\\\\Machine_learning.pdf', 'page': 47, 'start_index': 2004}\n",
      "\n",
      "Result 2\n",
      "performs tasks. The majority of the artificial neural networks will have some similarities with a more complex biological partner and are very effective at their expected tasks. For example, segmentation or classification. Feedback ANN: In this type of ANN, the output returns into the network to acc\n",
      "{'source': 'D:\\\\Coding\\\\Learning\\\\LLMs\\\\RAG\\\\Data\\\\Machine_learning.pdf', 'page': 48, 'start_index': 2011}\n",
      "\n",
      "Result 3\n",
      "not provide insight concerning why and how. It decreases trust in the network. Hardware dependence: Artificial neural networks need processors with parallel processing power, as per their structure. Therefore, the realization of the equipment is dependent. Difficulty of showing the issue to the netw\n",
      "{'source': 'D:\\\\Coding\\\\Learning\\\\LLMs\\\\RAG\\\\Data\\\\Machine_learning.pdf', 'page': 47, 'start_index': 1002}\n"
     ]
    }
   ],
   "source": [
    "query = \"what are neural networks?\"\n",
    "\n",
    "results = vector_db.similarity_search(query, k=3)\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"\\nResult {i}\")\n",
    "    print(doc.page_content[:300])\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f2a043",
   "metadata": {},
   "source": [
    "# Imports for LangGraph framework & workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29ec920ae9a62efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated, Literal, TypedDict, List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# LangChain Core\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Models\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_groq import ChatGroq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c74df9c",
   "metadata": {},
   "source": [
    "# Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba6d1a3b6c5d46ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouteQuery(BaseModel):\n",
    "    datasource: Literal[\"vectorstore\", \"llm_chat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1855a203",
   "metadata": {},
   "source": [
    "# Shared Mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae36c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    route_decision: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3201e1dd",
   "metadata": {},
   "source": [
    "# Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f95d07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "router_llm = ChatGroq(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0,\n",
    ")\n",
    "responder_llm = ChatGroq(\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8800f8",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0ebf6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_node(state: GraphState):\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "You are a STRICT routing engine, not a chatbot.\n",
    "\n",
    "Your ONLY job is to choose ONE word from the allowed options.\n",
    "\n",
    "ALLOWED OUTPUTS:\n",
    "vectorstore\n",
    "llm_chat\n",
    "\n",
    "RULES:\n",
    "- Output ONLY one word\n",
    "- No punctuation\n",
    "- No explanations\n",
    "- No extra text\n",
    "- No formatting\n",
    "- Do NOT repeat the question\n",
    "- Do NOT say both options\n",
    "- If unsure → llm_chat\n",
    "\n",
    "DECISION LOGIC:\n",
    "- vectorstore → ML concepts, algorithms, formulas, technical definitions\n",
    "- llm_chat → greetings, jokes, opinions, casual talk\n",
    "\"\"\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | router_llm\n",
    "    response = chain.invoke({\"question\": last_message})\n",
    "\n",
    "    raw_output = response.content.strip().lower()\n",
    "\n",
    "    print(\"\\n--- ROUTER RAW OUTPUT ---\")\n",
    "    print(raw_output)\n",
    "\n",
    "    # Strong normalization\n",
    "    if raw_output.startswith(\"vector\"):\n",
    "        decision = \"vectorstore\"\n",
    "    elif raw_output.startswith(\"llm\"):\n",
    "        decision = \"llm_chat\"\n",
    "    else:\n",
    "        decision = \"llm_chat\"  # fail-safe\n",
    "\n",
    "    print(f\"--- ROUTER DECISION --- {decision}\")\n",
    "\n",
    "    return {\"route_decision\": decision}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ecca8b",
   "metadata": {},
   "source": [
    "# Faiss Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "263a1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorstore_node(state: GraphState):\n",
    "    print(\"\\n--- [NODE] RAG: RETRIEVING FROM PDF ---\")\n",
    "\n",
    "    question = state[\"messages\"][-1].content\n",
    "    print(\"User Question:\", question)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # RETRIEVE\n",
    "    # -----------------------------------\n",
    "    docs = vector_db.similarity_search(question, k=3)\n",
    "\n",
    "    if not docs:\n",
    "        print(\"No documents retrieved\")\n",
    "        response = responder_llm.invoke(question)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    # -----------------------------------\n",
    "    # SHOW CONTEXT\n",
    "    # -----------------------------------\n",
    "    print(\"\\n--- RETRIEVED CONTEXT ---\")\n",
    "    context_parts = []\n",
    "\n",
    "    for i, d in enumerate(docs, 1):\n",
    "        snippet = d.page_content[:400].replace(\"\\n\", \" \")\n",
    "\n",
    "        print(f\"\\n[Chunk {i}]\")\n",
    "        print(snippet)\n",
    "        print(\"Metadata:\", d.metadata)\n",
    "\n",
    "        context_parts.append(d.page_content)\n",
    "\n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # PROMPT\n",
    "    # -----------------------------------\n",
    "    rag_prompt = f\"\"\"\n",
    "You are a Machine Learning assistant.\n",
    "\n",
    "Use ONLY the provided context to answer the question.\n",
    "If context is insufficient, say \"Context not sufficient.\"\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "    # -----------------------------------\n",
    "    # RESPONSE\n",
    "    # -----------------------------------\n",
    "    response = responder_llm.invoke(rag_prompt)\n",
    "\n",
    "    print(\"\\n--- FINAL ANSWER ---\")\n",
    "    print(response.content)\n",
    "\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b951d3",
   "metadata": {},
   "source": [
    "## Chat & Conditional node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f90eed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_chat_node(state: GraphState):\n",
    "    response = responder_llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "def decide_next_node(state: GraphState):\n",
    "    decision = state[\"route_decision\"]\n",
    "\n",
    "    if decision == \"vectorstore\":\n",
    "        return \"vectorstore\"\n",
    "\n",
    "    return \"llm_chat\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b82679",
   "metadata": {},
   "source": [
    "# Build graph and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "642da286",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"router\", router_node)\n",
    "workflow.add_node(\"vectorstore\", vectorstore_node)\n",
    "workflow.add_node(\"llm_chat\", llm_chat_node)\n",
    "\n",
    "workflow.add_edge(START, \"router\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"router\",\n",
    "    decide_next_node,\n",
    "    {\n",
    "        \"vectorstore\": \"vectorstore\",\n",
    "        \"llm_chat\": \"llm_chat\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"vectorstore\", END)\n",
    "workflow.add_edge(\"llm_chat\", END)\n",
    "\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ef6a2",
   "metadata": {},
   "source": [
    "# Visualize the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "60b09833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ca736e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ROUTER RAW OUTPUT ---\n",
      "vectorstore\n",
      "--- ROUTER DECISION --- vectorstore\n",
      "\n",
      "--- [NODE] RAG: RETRIEVING FROM PDF ---\n",
      "User Question: What are KD-trees.\n",
      "\n",
      "--- RETRIEVED CONTEXT ---\n",
      "\n",
      "[Chunk 1]\n",
      "very simple. You create a binary tree by choosing one dimension at a time to split into two, and placing the line through the median of the point coordinates of that dimension. The points themselves end up as leaves of the tree. Making the tree follows pretty much the same steps as usual for constructing a binary tree: we identify a place to split into two choices, left and right, and then carry o\n",
      "Metadata: {'source': 'D:\\\\Coding\\\\Learning\\\\LLMs\\\\RAG\\\\Data\\\\Machine_learning.pdf', 'page': 84, 'start_index': 1002}\n",
      "\n",
      "[Chunk 2]\n",
      "82 FIGURE 8: The splits and leaf points found by the KD-tree. FIGURE 9: The KD-tree that made the splits. Searching the tree is the same as any other binary tree; we are more interested in finding the nearest neighbours of a test point. This is fairly easy: starting at the root of the tree you recurse down through the tree comparing just one dimension at a time until you find a leaf node that is i\n",
      "Metadata: {'source': 'D:\\\\Coding\\\\Learning\\\\LLMs\\\\RAG\\\\Data\\\\Machine_learning.pdf', 'page': 86, 'start_index': 0}\n",
      "\n",
      "[Chunk 3]\n",
      "80 FIGURE 6: Output of the nearest neighbour method and two kernel smoothers on the data of duration and repose of eruptions of Mount Ruapehu 1860–2006. 3.12 Efficient Distance Computations: the KD-Tree As was mentioned above, computing the distances between all pairs of points is very computationally expensive. Fortunately, as with many problems in computer science, designing an efficient data st\n",
      "Metadata: {'source': 'D:\\\\Coding\\\\Learning\\\\LLMs\\\\RAG\\\\Data\\\\Machine_learning.pdf', 'page': 84, 'start_index': 0}\n",
      "\n",
      "--- FINAL ANSWER ---\n",
      "KD-trees are a data structure used for efficiently finding the nearest neighbours of a test point. They are a type of binary tree constructed by recursively splitting the data into two subsets based on one dimension at a time, with the split occurring at the median of the point coordinates in that dimension. This allows for fast searching and nearest neighbour finding, with a cost of O(log N) and O(N) storage. The construction of the tree has a cost of O(N log2 N).\n",
      "KD-trees are a data structure used for efficiently finding the nearest neighbours of a test point. They are a type of binary tree constructed by recursively splitting the data into two subsets based on one dimension at a time, with the split occurring at the median of the point coordinates in that dimension. This allows for fast searching and nearest neighbour finding, with a cost of O(log N) and O(N) storage. The construction of the tree has a cost of O(N log2 N).\n"
     ]
    }
   ],
   "source": [
    "result = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What are KD-trees.\")]\n",
    "})\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefb8a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
